### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognitionEngine
  id: SpeechRecognitionEngine
  children:
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  - System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  - System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  - System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  - System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  - System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  - System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  - System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  - System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  - System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  langs:
  - csharp
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine
  fullName: System.Speech.Recognition.SpeechRecognitionEngine
  type: Class
  summary: "Ger möjlighet att komma åt och hantera taligenkänningsmotor i processen."
  remarks: "Du kan skapa en instans av den här klassen för någon av de installerade taligenkänning. För att få information om vilka är installerade, använder du statiskhet <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       Den här klassen gäller körs speech recognition motorer i processen och ger kontroll över olika aspekter av taligenkänning, enligt följande: – Om du vill skapa en pågående taligenkänningen ska du använda en av de <xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>konstruktorer.</xref:System.Speech.Recognition.SpeechRecognitionEngine.%23ctor%2A>      -Om du vill hantera speech recognition grammatik, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>metoder och <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>egenskap.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>      -Konfigurera indata till tolken med den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>, eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>      -Om du vill utföra taligenkänning måste använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>      -Om du vill ändra hur recognition hanterar tystnad eller oväntat indata, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Egenskaper.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Du kan ändra antalet ersättare tolken returnerar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A>egenskapen.</xref:System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates%2A> Tolken returnerar resultat i en <xref:System.Speech.Recognition.RecognitionResult>objektet.</xref:System.Speech.Recognition.RecognitionResult>      -Om du vill synkronisera ändringar i tolken, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Tolken använder mer än en tråd för att utföra uppgifter.      – För att emulera indata till tolken, den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>       Objektet SpeechRecognitionEngine är användas för processen som instansieras objektet. Som kontrast, <xref:System.Speech.Recognition.SpeechRecognizer>delar ett enda tolken med alla program som vill använda det.</xref:System.Speech.Recognition.SpeechRecognizer>      > [!NOTE] > Alltid anropet <xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A>innan du släpper ditt senaste referens till taligenkänningen.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Dispose%2A> Annars resurser den använder frigörs inte förrän skräpinsamlingen anropar tolken objektets `Finalize` metod."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. Because this example uses the `Multiple` mode of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> method, it performs recognition until you close the console window or stop debugging.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: 'public class SpeechRecognitionEngine : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Initierar en ny instans av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> klassen använder taligenkänningen standard för systemet."
  remarks: "Innan taligenkänningen kan taligenkänning kan du läsa in minst en recognition grammatik och konfigurera indata för tolkning.       För att läsa in en grammatik anropa den <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Använd någon av följande metoder för att konfigurera ljud indata:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  syntax:
    content: public SpeechRecognitionEngine ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  id: '#ctor(System.Globalization.CultureInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Initierar en ny instans av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> klassen med taligenkänningen standard för ett angivet språk."
  remarks: "Microsoft Windows och System.Speech API acceptera alla giltiga språk-landskoder. Att utföra taligenkänning med hjälp av det språk som anges i den `CultureInfo` argumentet, ett taligenkänningsmotorn som har stöd för språket landskod måste vara installerad. Taligenkänningsmotorer som levereras med Microsoft Windows 7 arbeta med följande språk-landskoder.      -en-GB. Engelska (Storbritannien) - en-US. Engelska (USA) - de-DE. Tyska (Tyskland) - es-ES. Spanska (Spanien) - fr-FR. Franska (Frankrike) - ja-JP. Japanska (Japan) - zh-CN. Kinesiska (Kina) - zh-TW. Kinesiska (Taiwan) två bokstäver språkkoder, till exempel &quot;SV&quot;, &quot;fr&quot; eller &quot;es&quot; får heller.       Innan taligenkänningen kan recognition kan du läsa in minst en speech recognition grammatik och konfigurera indata för tolkning.       För att läsa in en grammatik anropa den <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Använd någon av följande metoder för att konfigurera ljud indata:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer for the en-US locale.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Globalization.CultureInfo culture);
    parameters:
    - id: culture
      type: System.Globalization.CultureInfo
      description: "Det språk som måste ha stöd för taligenkänningen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "Ingen av de installerade taligenkänning stöder den angivna, eller <code> culture </code> är den invariabla kulturen."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Culture</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  id: '#ctor(System.Speech.Recognition.RecognizerInfo)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Initierar en ny instans av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> med hjälp av informationen i en <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> objekt för att ange tolk för att använda."
  remarks: "Du kan skapa en instans av den här klassen för någon av de installerade taligenkänning. För att få information om vilka är installerade, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       Innan taligenkänningen kan recognition kan du läsa in minst en speech recognition grammatik och konfigurera indata för tolkning.       För att läsa in en grammatik anropa den <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Använd någon av följande metoder för att konfigurera ljud indata:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and initializes a speech recognizer that supports the English language.  \n  \n```c#  \n using System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public SpeechRecognitionEngine (System.Speech.Recognition.RecognizerInfo recognizerInfo);
    parameters:
    - id: recognizerInfo
      type: System.Speech.Recognition.RecognizerInfo
      description: "Information för specifika taligenkänningen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  id: '#ctor(System.String)'
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Initierar en ny instans av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> klass med en strängparameter som anger namnet på tolk för att använda."
  remarks: "Namnet på token tolken är värdet för den <xref:System.Speech.Recognition.RecognizerInfo.Id%2A>-egenskapen för den <xref:System.Speech.Recognition.RecognizerInfo>objektet som returnerades av den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>egenskapen för tolken.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A> </xref:System.Speech.Recognition.RecognizerInfo> </xref:System.Speech.Recognition.RecognizerInfo.Id%2A> För att få en samling med alla installerade identifierare, använder du statiskhet <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>       Innan taligenkänningen kan recognition kan du läsa in minst en speech recognition grammatik och konfigurera indata för tolkning.       För att läsa in en grammatik anropa den <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>       Använd någon av följande metoder för att konfigurera ljud indata:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition, and creates an instance of the Speech Recognizer 8.0 for Windows (English - US).  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an instance of the Microsoft Speech Recognizer 8.0 for  \n      // Windows (English - US).  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(\"MS-1033-80-DESK\"))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized += new EventHandler(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognitionEngine (string recognizerId);
    parameters:
    - id: recognizerId
      type: System.String
      description: "Namnet på token för taligenkänningen ska användas."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  exceptions:
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "Inga taligenkänningen med det token-namnet installeras, eller <code> recognizerId </code> är en tom sträng (&quot;&quot;)."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>recognizerId</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar formatet för ljud tas emot av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Använd någon av följande metoder för att konfigurera ljud indata:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>"
  example:
  - "The example below uses AudioFormat to obtain and display audio format data.  \n  \n```  \nstatic void DisplayAudioDeviceFormat(Label label, SpeechRecognitionEngine recognitionEngine)   \n{  \n  \n  if (recognitionEngine != null && label != null)   \n  {  \n    label.Text = String.Format(\"Encoding Format:         {0}\\n\" +  \n          \"AverageBytesPerSecond    {1}\\n\" +  \n          \"BitsPerSample            {2}\\n\" +  \n          \"BlockAlign               {3}\\n\" +  \n          \"ChannelCount             {4}\\n\" +  \n          \"SamplesPerSecond         {5}\",  \n          recognitionEngine.AudioFormat.EncodingFormat.ToString(),  \n          recognitionEngine.AudioFormat.AverageBytesPerSecond,  \n          recognitionEngine.AudioFormat.BitsPerSample,  \n          recognitionEngine.AudioFormat.BlockAlign,  \n          recognitionEngine.AudioFormat.ChannelCount,  \n          recognitionEngine.AudioFormat.SamplesPerSecond);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "Formatet för ljud på indata för den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> instans, eller <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> om indata inte är konfigurerad eller inställt på null-indata."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar nivån för den tas emot av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Värdet 0 representerar tystnad och 100 representerar maximala volymen."
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "Ljud andelen indata för taligenkänningen, mellan 0 och 100."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> rapporterar nivån av dess ljudinsignal."
  remarks: "Den <xref:System.Speech.Recognition.SpeechRecognitionEngine>skapat händelsen flera gånger per sekund.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Den frekvens som händelsen visas beror på den dator där programmet körs.       För att få nivån ljud vid tidpunkten för händelsen, använder du <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>egenskapen i associerade <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs> </xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> Om du vill skaffa den aktuella ljud indata till tolken, använder du tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>egenskap.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A>       När du skapar en AudioLevelUpdated delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example adds a handler for the AudioLevelUpdated event to a <xref:System.Speech.Recognition.SpeechRecognitionEngine> object. The handler outputs the new audio level to the console.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the SpeechRecognitionEngine object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n   new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar den aktuella platsen i ljudström som skapas av den enhet som tillhandahåller indata för den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Egenskapen AudioPosition refererar inkommande enhetens position i den genererade ljudströmmen. Däremot kommer den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>refererar till den tolken position inom dess ljudinsignal.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> Dessa platser kan vara olika. Till exempel om tolken har tagit emot indata för vilka det har inte ännu genereras ett recognition resultat och värdet för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>egenskapen är mindre än värdet på egenskapen AudioPosition.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>"
  example:
  - "In the following example, the in-process speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine for US English.  \n      using (recognizer = new SpeechRecognitionEngine(  \n        new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create a grammar for finding services in different cities.  \n        Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n        Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n        GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n        findServices.Append(services);  \n        findServices.Append(\"near\");  \n        findServices.Append(cities);  \n  \n        // Create a Grammar object from the GrammarBuilder and load it to the recognizer.  \n        Grammar servicesGrammar = new Grammar(findServices);  \n        recognizer.LoadGrammarAsync(servicesGrammar);  \n  \n        // Add handlers for events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position at the event: \" + e.AudioPosition);  \n      Console.WriteLine(\"  Current audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Current recognizer audio position: \" +   \n        recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"\\nSpeech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "Den aktuella platsen i ljudström som skapas av inkommande enheten."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> identifierar ett problem i ljud signalen."
  remarks: "Använd <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>egenskapen för den associera <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> </xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> för att få vilka problem uppstod       När du skapar en AudioSignalProblemOccurred delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example defines an event handler that gathers information about an AudioSignalProblemOccurred event.  \n  \n```  \nprivate SpeechRecognitionEngine recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognitionEngine();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar status för ljud tas emot av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Egenskapen AudioState representerar tillståndet ljud med en medlem i den <xref:System.Speech.Recognition.AudioState>uppräkningen.</xref:System.Speech.Recognition.AudioState>"
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "Status för ljud indata för taligenkänningen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inträffar när tillståndsändringar i ljuduppspelningen tas emot av den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "För att få ljud tillståndet vid tidpunkten för händelsen, använder du <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>egenskapen i associerade <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</xref:System.Speech.Recognition.AudioStateChangedEventArgs> </xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> För att hämta indata till tolken aktuella ljud tillstånd, använder du tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A>egenskap.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> Mer information om ljud tillstånd finns det <xref:System.Speech.Recognition.AudioState>uppräkningen.</xref:System.Speech.Recognition.AudioState>       När du skapar en AudioStateChanged delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example uses a handler for the AudioStateChanged event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioState%2A> to the console each time it changes, using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(\"On this farm he had a\");  \n        farm.Append(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  id: BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar eller anger tidsintervallet under vilka en <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> accepterar indata som innehåller endast bakgrundsljud, innan du slutför igenkänning."
  remarks: "Varje taligenkänningen har en algoritm för att skilja mellan tystnad och tal. Tolken klassificerar som bakgrundsljud alla tystnad indata som inte matchar inledande regeln för någon av tolken läses in och aktiverat tal recognition grammatik. Om tolken får endast bakgrundsljud och tystnad innan timeout babble, Slutför tolken recognition åtgärden.      -För igenkänning av asynkrona åtgärder tolken genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>händelse, där den <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName>egenskapen är `true`, och <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>egenskapen är `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      -För synkron recognition åtgärder och emulering, tolken returnerar `null`, i stället för ett giltigt <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult>       Om tidsgränsen babble anges till 0 tolken inte att utföra en babble timeout-kontroll. Timeout-intervall kan vara ett negativt värde. Standardvärdet är 0 sekunder."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition that sets the BabbleTimeout and <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan BabbleTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "Varaktighet för tidsintervallet."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Den här egenskapen anges till mindre än 0 sekunder."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Förfogar den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objekt."
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Förfogar den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objekt och versioner av de resurser som används under sessionen."
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>Frisläpp både hanterade och ohanterade resurser. <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref> att släppa endast resurser som inte hanteras."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emulerar indata av en fras för taligenkänningen via SMS i stället för ljud för synkron taligenkänning."
  remarks: "Speech recognizer aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelser som om åtgärden recognition inte emuleras.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       Identifierare som levereras med Vista och Windows 7 Ignorera skiftläge och tecknet bredd när du använder grammatik regler för inkommande frasen. Mer information om den här typen av jämförelse finns i <xref:System.Globalization.CompareOptions>uppräkningen värden <xref:System.Globalization.CompareOptions>och <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Identifierarna också Ignorera nya rader och extra blanksteg och skiljetecken behandlas som litteralt indata."
  example:
  - "The code example below is part of a console application that demonstrates emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \nTestRecognize(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n...Recognition result text = Smith  \n  \nTestRecognize(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n...Recognition result text = Jones  \n  \nTestRecognize(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n...No recognition result.  \n  \nTestRecognize(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n...Recognition result text = mister Smith  \n  \npress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace Sre_EmulateRecognize  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Disable audio input to the recognizer.  \n        recognizer.SetInputToNull();  \n  \n        // Add handlers for events raised by the EmulateRecognize method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n  \n        // Start four synchronous emulated recognition operations.  \n        TestRecognize(recognizer, \"Smith\");  \n        TestRecognize(recognizer, \"Jones\");  \n        TestRecognize(recognizer, \"Mister\");  \n        TestRecognize(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for synchronous recognition.  \n    private static void TestRecognize(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      Console.WriteLine(\"TestRecognize(\\\"{0}\\\")...\", input);  \n      RecognitionResult result =  \n        recognizer.EmulateRecognize(input,CompareOptions.IgnoreCase);  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"...Recognition result text = {0}\",  \n          result.Text ?? \"<null>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"...No recognition result.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    // Handle events.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "Indata för igenkänning igen."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Resultatet för igenkänning-åtgärden eller <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> om det går inte att genomföra åtgärden eller tolken är inte aktiverad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Identifieraren har inga speech recognition grammatik läses in."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>är en tom sträng (&quot;&quot;)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emulerar indata för specifika ord för taligenkänningen via SMS i stället för ljud för synkron taligenkänning och anger hur tolken hanterar Unicode jämförelse mellan orden och läsa in speech recognition grammatik."
  remarks: "Speech recognizer aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelser som om åtgärden recognition inte emuleras.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       Tolken använder `compareOptions` när det gäller grammatik regler för inkommande frasen. Identifierare som levereras med Vista och Windows 7 Ignorera skiftläge om den <xref:System.Globalization.CompareOptions>eller <xref:System.Globalization.CompareOptions>värdet finns.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Tolken ignorerar alltid teckenbredden och aldrig ignorerar Kana-typen. Tolken också ignorerar nya rader och extra blanksteg och skiljetecken behandlas som litteralt indata. Läs mer om teckenbredden och Kana-typ, den <xref:System.Globalization.CompareOptions>uppräkningen.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "En matris med word enheter som innehåller indata för igenkänning igen."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "En binär kombination av uppräkningsvärdena som beskriver typ av jämförelse som ska användas för emulerade recognition igen."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Resultatet för igenkänning-åtgärden eller <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> om det går inte att genomföra åtgärden eller tolken är inte aktiverad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Identifieraren har inga speech recognition grammatik läses in."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>innehåller en eller flera <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> element."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>innehåller den <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, eller <xref:System.Globalization.CompareOptions> flaggan."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emulerar indata av en fras för taligenkänningen via SMS i stället för ljud för synkron taligenkänning och anger hur tolken hanterar Unicode jämförelse mellan frasen och läsa in speech recognition grammatik."
  remarks: "Speech recognizer aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelser som om åtgärden recognition inte emuleras.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>       Tolken använder `compareOptions` när det gäller grammatik regler för inkommande frasen. Identifierare som levereras med Vista och Windows 7 Ignorera skiftläge om den <xref:System.Globalization.CompareOptions>eller <xref:System.Globalization.CompareOptions>värdet finns.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Tolken ignorerar alltid teckenbredden och aldrig ignorerar Kana-typen. Tolken också ignorerar nya rader och extra blanksteg och skiljetecken behandlas som litteralt indata. Läs mer om teckenbredden och Kana-typ, den <xref:System.Globalization.CompareOptions>uppräkningen.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "Inkommande frasen för igenkänning igen."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "En binär kombination av uppräkningsvärdena som beskriver typ av jämförelse som ska användas för emulerade recognition igen."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Resultatet för igenkänning-åtgärden eller <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> om det går inte att genomföra åtgärden eller tolken är inte aktiverad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Identifieraren har inga speech recognition grammatik läses in."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>är en tom sträng (&quot;&quot;)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>innehåller den <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, eller <xref:System.Globalization.CompareOptions> flaggan."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emulerar indata av en fras för taligenkänningen via SMS i stället för ljud för asynkron taligenkänning."
  remarks: "Speech recognizer aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelser som om åtgärden recognition inte emuleras.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> När tolken är klar asynkron recognition åtgärden genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       Identifierare som levereras med Vista och Windows 7 Ignorera skiftläge och tecknet bredd när du använder grammatik regler för inkommande frasen. Mer information om den här typen av jämförelse finns i <xref:System.Globalization.CompareOptions>uppräkningen värden <xref:System.Globalization.CompareOptions>och <xref:System.Globalization.CompareOptions>.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Identifierarna också Ignorera nya rader och extra blanksteg och skiljetecken behandlas som litteralt indata."
  example:
  - "The code example below is part of a console application that demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. The example generates the following output.  \n  \n```  \n  \nTestRecognizeAsync(\"Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = Smith  \n Done.  \n  \nTestRecognizeAsync(\"Jones\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Jones; Text = Jones  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Jones; Text = Jones  \n Done.  \n  \nTestRecognizeAsync(\"Mister\")...  \n SpeechDetected event raised.  \n SpeechHypothesized event raised.  \n  Grammar = Smith; Text = mister  \n SpeechRecognitionRejected event raised.  \n  Grammar = <not available>; Text =  \n EmulateRecognizeCompleted event raised.  \n  No recognition result available.  \n Done.  \n  \nTestRecognizeAsync(\"Mister Smith\")...  \n SpeechDetected event raised.  \n SpeechRecognized event raised.  \n  Grammar = Smith; Text = mister Smith  \n EmulateRecognizeCompleted event raised.  \n  Grammar = Smith; Text = mister Smith  \n Done.  \n  \npress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SreEmulateRecognizeAsync  \n{  \n  class Program  \n  {  \n    // Indicate when an asynchronous operation is finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Load grammars.  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Smith\"));  \n        recognizer.LoadGrammar(CreateNameGrammar(\"Jones\"));  \n  \n        // Configure the audio input.  \n        recognizer.SetInputToNull();  \n  \n        // Add event handlers for the events raised by the  \n        // EmulateRecognizeAsync method.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHander);  \n  \n        // Start four asynchronous emulated recognition operations.  \n        TestRecognizeAsync(recognizer, \"Smith\");  \n        TestRecognizeAsync(recognizer, \"Jones\");  \n        TestRecognizeAsync(recognizer, \"Mister\");  \n        TestRecognizeAsync(recognizer, \"Mister Smith\");  \n      }  \n  \n      Console.WriteLine(\"press any key to exit...\");  \n      Console.ReadKey(true);  \n    }  \n  \n    // Create a simple name grammar.  \n    // Set the grammar name to the surname.  \n    private static Grammar CreateNameGrammar(string surname)  \n    {  \n      GrammarBuilder builder = new GrammarBuilder(\"mister\", 0, 1);  \n      builder.Append(surname);  \n  \n      Grammar nameGrammar = new Grammar(builder);  \n      nameGrammar.Name = surname;  \n  \n      return nameGrammar;  \n    }  \n  \n    // Send emulated input to the recognizer for asynchronous  \n    // recognition.  \n    private static void TestRecognizeAsync(  \n      SpeechRecognitionEngine recognizer, string input)  \n    {  \n      completed = false;  \n  \n      Console.WriteLine(\"TestRecognizeAsync(\\\"{0}\\\")...\", input);  \n      recognizer.EmulateRecognizeAsync(input);  \n  \n      // Wait for the operation to complete.  \n      while (!completed)  \n      {  \n        Thread.Sleep(333);  \n      }  \n  \n      Console.WriteLine(\" Done.\");  \n      Console.WriteLine();  \n    }  \n  \n    static void SpeechDetectedHandler(  \n      object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechDetected event raised.\");  \n    }  \n  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechHypothesized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    // Handle events.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognitionRejected event raised.\");  \n      if (e.Result != null)  \n      {  \n        string grammarName;  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name ?? \"<none>\";  \n        }  \n        else  \n        {  \n          grammarName = \"<not available>\";  \n        }  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          grammarName, e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" SpeechRecognized event raised.\");  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text );  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n    }  \n  \n    static void EmulateRecognizeCompletedHander(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" EmulateRecognizeCompleted event raised.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  {0} exception encountered: {1}:\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      else if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      else if (e.Result != null)  \n      {  \n        Console.WriteLine(\"  Grammar = {0}; Text = {1}\",  \n          e.Result.Grammar.Name ?? \"<none>\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  No recognition result available.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "Indata för igenkänning igen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Tolken har inga speech recognition grammatik som lästs in, eller tolken har en asynkron recognition åtgärd som inte ännu slutförts."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>är en tom sträng (&quot;&quot;)."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emulerar indata för specifika ord för taligenkänningen med hjälp av en matris med <xref href=&quot;System.Speech.Recognition.RecognizedWordUnit&quot;> </xref> objekt i stället för ljud för asynkron taligenkänning och anger hur tolken hanterar Unicode jämförelse mellan orden och läsa in speech recognition grammatik."
  remarks: "Speech recognizer aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelser som om åtgärden recognition inte emuleras.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> När tolken är klar asynkron recognition åtgärden genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       Tolken använder `compareOptions` när det gäller grammatik regler för inkommande frasen. Identifierare som levereras med Vista och Windows 7 Ignorera skiftläge om den <xref:System.Globalization.CompareOptions>eller <xref:System.Globalization.CompareOptions>värdet finns.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Identifierarna Ignorera alltid teckenbredden och aldrig Ignorera Kana-typen. Identifierarna också Ignorera nya rader och extra blanksteg och skiljetecken behandlas som litteralt indata. Läs mer om teckenbredden och Kana-typ, den <xref:System.Globalization.CompareOptions>uppräkningen.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "En matris med word enheter som innehåller indata för igenkänning igen."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "En binär kombination av uppräkningsvärdena som beskriver typ av jämförelse som ska användas för emulerade recognition igen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Tolken har inga speech recognition grammatik som lästs in, eller tolken har en asynkron recognition åtgärd som inte ännu slutförts."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>wordUnits</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>wordUnits</code>innehåller en eller flera <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> element."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>innehåller den <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, eller <xref:System.Globalization.CompareOptions> flaggan."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Emulerar indata av en fras för taligenkänningen via SMS i stället för ljud för asynkron taligenkänning och anger hur tolken hanterar Unicode jämförelse mellan frasen och läsa in speech recognition grammatik."
  remarks: "Speech recognizer aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelser som om åtgärden recognition inte emuleras.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> När tolken är klar asynkron recognition åtgärden genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>       Tolken använder `compareOptions` när det gäller grammatik regler för inkommande frasen. Identifierare som levereras med Vista och Windows 7 Ignorera skiftläge om den <xref:System.Globalization.CompareOptions>eller <xref:System.Globalization.CompareOptions>värdet finns.</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> Identifierarna Ignorera alltid teckenbredden och aldrig Ignorera Kana-typen. Identifierarna också Ignorera nya rader och extra blanksteg och skiljetecken behandlas som litteralt indata. Läs mer om teckenbredden och Kana-typ, den <xref:System.Globalization.CompareOptions>uppräkningen.</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "Inkommande frasen för igenkänning igen."
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "En binär kombination av uppräkningsvärdena som beskriver typ av jämförelse som ska användas för emulerade recognition igen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  exceptions:
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Tolken har inga speech recognition grammatik som lästs in, eller tolken har en asynkron recognition åtgärd som inte ännu slutförts."
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>inputText</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>inputText</code>är en tom sträng (&quot;&quot;)."
  - type: System.NotSupportedException
    commentId: T:System.NotSupportedException
    description: "<code>compareOptions</code>innehåller den <xref:System.Globalization.CompareOptions>, <xref:System.Globalization.CompareOptions>, eller <xref:System.Globalization.CompareOptions> flaggan."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> Slutför en asynkron recognition åtgärd emulerade indata."
  remarks: "Varje <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>metoden börjar en asynkron recognition åtgärd.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> Den <xref:System.Speech.Recognition.SpeechRecognitionEngine>genererar EmulateRecognizeCompleted händelsen när den Slutför den asynkrona åtgärden.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       Den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>åtgärden kan öka den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelser.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> Händelsen EmulateRecognizeCompleted är sist sådan händelse att tolken genererar för en viss åtgärd.       Om emulerade recognition lyckades, du kan komma åt recognition resultatet med något av följande: - <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>egenskap i den <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>objekt i hanteraren för händelsen EmulateRecognizeCompleted.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> </xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>      - <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>egenskap i den <xref:System.Speech.Recognition.SpeechRecognizedEventArgs>objekt i hanteraren för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       Om emulerade recognition inte lyckades, i <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelse utlöses inte och <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A>är null.</xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs.Result%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       <xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>härleds från <xref:System.ComponentModel.AsyncCompletedEventArgs>.</xref:System.ComponentModel.AsyncCompletedEventArgs></xref:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>       <xref:System.Speech.Recognition.SpeechRecognizedEventArgs>härleds från <xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs></xref:System.Speech.Recognition.SpeechRecognizedEventArgs>       När du skapar en EmulateRecognizeCompleted delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InProcessRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of an in-process recognizer.  \n      using (SpeechRecognitionEngine recognizer =   \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call mathches the grammar  \n        // and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Result of 1st call to EmulateRecognizeAsync = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"Result of 2nd call to EmulateRecognizeAsync = No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  id: EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar eller anger intervallet tystnad som den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> accepterar i slutet av entydigt indata innan du slutför en recognition-åtgärd."
  remarks: "Taligenkänningsmotorn används timeout-intervall om recognition indata är tvetydigt. Exempelvis för en speech recognition grammatik som stöd för identifiering av antingen &quot;nytt spel du&quot; eller &quot;nytt spel&quot;, &quot;nya spel du&quot; entydigt indata och &quot;nytt spel&quot; är tvetydig indata.       Den här egenskapen anger hur länge taligenkänningsmotorn väntar för ytterligare information innan du slutför en recognition-åtgärd. Timeout-intervall kan vara från 0 sekunder till 10 sekunder. Standardvärdet är 150 millisekunder.       Om du vill ange timeout för tvetydig indata, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>egenskapen.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "Varaktighet för intervallet tystnad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Den här egenskapen anges till mindre än 0 sekunder eller mer än 10 sekunder."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  id: EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar eller anger intervallet tystnad som den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> accepterar i slutet av tvetydig indata innan du slutför en recognition-åtgärd."
  remarks: "Taligenkänningsmotorn används timeout-intervall om recognition indata är tvetydig. Exempelvis för en speech recognition grammatik som stöd för identifiering av antingen &quot;nytt spel du&quot; eller &quot;nytt spel&quot;, &quot;nya spel du&quot; entydigt indata och &quot;nytt spel&quot; är tvetydig indata.       Den här egenskapen anger hur länge taligenkänningsmotorn väntar för ytterligare information innan du slutför en recognition-åtgärd. Timeout-intervall kan vara från 0 sekunder till 10 sekunder. Standardvärdet är 500 millisekunder.       Om du vill ange timeout för entydigt indata, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>egenskapen.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>"
  syntax:
    content: public TimeSpan EndSilenceTimeoutAmbiguous { get; set; }
    return:
      type: System.TimeSpan
      description: "Varaktighet för intervallet tystnad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Den här egenskapen anges till mindre än 0 sekunder eller mer än 10 sekunder."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar en samling av <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt som lästs in i den här <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> instans."
  remarks: ''
  example:
  - "The following example outputs information to the console for each speech recognition grammar that is currently loaded by a speech recognizer.  \n  \n> [!IMPORTANT]\n>  Copy the grammar collection to avoid errors if the collection is modified while this method enumerates the elements of the collection.  \n  \n```c#  \n  \nprivate static void ListGrammars(SpeechRecognitionEngine recognizer)  \n{  \n  string qualifier;  \n  List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n  foreach (Grammar g in grammars)  \n  {  \n    qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n  \n    Console.WriteLine(\"Grammar {0} is loaded and is {1}.\",  \n      g.Name, qualifier);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "Insamling av <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  id: InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar eller anger tidsintervallet under vilka en <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> accepterar indata som innehåller endast tystnad innan du slutför igenkänning."
  remarks: "Varje taligenkänningen har en algoritm för att skilja mellan tystnad och tal. Om tolken indata tystnad vid tidsgränsen för inledande tystnad, Slutför tolken recognition åtgärden.      -För igenkänning av asynkrona åtgärder och emulering, tolken genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>händelse, där den <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName>egenskapen är `true`, och <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName>egenskapen är `null`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A?displayProperty=fullName> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A?displayProperty=fullName> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>      -För synkron recognition åtgärder och emulering, tolken returnerar `null`, i stället för ett giltigt <xref:System.Speech.Recognition.RecognitionResult>.</xref:System.Speech.Recognition.RecognitionResult>       Om inledande tystnad timeout-intervall har angetts till 0 tolken inte att utföra en inledande tystnad timeout-kontroll. Timeout-intervall kan vara ett negativt värde. Standardvärdet är 0 sekunder."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example sets the <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> and InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> before initiating speech recognition. Handlers for the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> events output event information to the console to demonstrate how the InitialSilenceTimeout properties of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> properties affect recognition operations.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Load a Grammar object.  \n        recognizer.LoadGrammar(CreateServicesGrammar(\"FindServices\"));  \n  \n        // Add event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(  \n            AudioStateChangedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(3);  \n        recognizer.BabbleTimeout = TimeSpan.FromSeconds(2);  \n        recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1);  \n        recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.5);  \n  \n        Console.WriteLine(\"BabbleTimeout: {0}\", recognizer.BabbleTimeout);  \n        Console.WriteLine(\"InitialSilenceTimeout: {0}\", recognizer.InitialSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeout: {0}\", recognizer.EndSilenceTimeout);  \n        Console.WriteLine(\"EndSilenceTimeoutAmbiguous: {0}\", recognizer.EndSilenceTimeoutAmbiguous);  \n        Console.WriteLine();  \n  \n        // Start asynchronous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Single);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Create a grammar and build it into a Grammar object.   \n    static Grammar CreateServicesGrammar(string grammarName)  \n    {  \n  \n      // Create a grammar for finding services in different cities.  \n      Choices services = new Choices(new string[] { \"restaurants\", \"hotels\", \"gas stations\" });  \n      Choices cities = new Choices(new string[] { \"Seattle\", \"Boston\", \"Dallas\" });  \n  \n      GrammarBuilder findServices = new GrammarBuilder(\"Find\");  \n      findServices.Append(services);  \n      findServices.Append(\"near\");  \n      findServices.Append(cities);  \n  \n      // Create a Grammar object from the GrammarBuilder..  \n      Grammar servicesGrammar = new Grammar(findServices);  \n      servicesGrammar.Name = (\"FindServices\");  \n      return servicesGrammar;  \n    }  \n  \n    // Handle the AudioStateChanged event.  \n    static void AudioStateChangedHandler(  \n      object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"AudioStateChanged ({0}): {1}\",  \n        DateTime.Now.ToString(\"mm:ss.f\"), e.AudioState);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"RecognizeCompleted ({0}):\",  \n        DateTime.Now.ToString(\"mm:ss.f\"));  \n  \n      string resultText;  \n      if (e.Result != null) { resultText = e.Result.Text; }  \n      else { resultText = \"<null>\"; }  \n  \n      Console.WriteLine(  \n        \" BabbleTimeout: {0}; InitialSilenceTimeout: {1}; Result text: {2}\",  \n        e.BabbleTimeout, e.InitialSilenceTimeout, resultText);  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\" Exception message: \", e.Error.Message);  \n      }  \n  \n      // Start the next asynchronous recognition operation.  \n      ((SpeechRecognitionEngine)sender).RecognizeAsync(RecognizeMode.Single);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan InitialSilenceTimeout { get; set; }
    return:
      type: System.TimeSpan
      description: "Varaktighet för intervallet tystnad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "Den här egenskapen anges till mindre än 0 sekunder."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  id: InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Returnerar information för alla installerade taligenkänning i systemet."
  remarks: "För att få information om aktuella tolken kan använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>egenskapen.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses the collection returned by the InstalledRecognizers method to find a speech recognizer that supports the English language.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Select a speech recognizer that supports English.  \n      RecognizerInfo info = null;  \n      foreach (RecognizerInfo ri in SpeechRecognitionEngine.InstalledRecognizers())  \n      {  \n        if (ri.Culture.TwoLetterISOLanguageName.Equals(\"en\"))  \n        {  \n          info = ri;  \n          break;  \n        }  \n      }  \n      if (info == null) return;  \n  \n      // Create the selected recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(info))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public static System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo> InstalledRecognizers ();
    parameters: []
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
      description: "En skrivskyddad samling av <xref href=&quot;System.Speech.Recognition.RecognizerInfo&quot;> </xref> objekt som beskriver de installerade identifierarna."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Synkront läser in en <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt."
  remarks: "Tolken genererar ett undantag om den <xref:System.Speech.Recognition.Grammar>objekt har redan lästs in, läses asynkront eller gick inte att läsa in i alla tolken.</xref:System.Speech.Recognition.Grammar> Du kan inte läsa in samma <xref:System.Speech.Recognition.Grammar>objekt till flera instanser av <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> I stället skapa ett nytt <xref:System.Speech.Recognition.Grammar>objekt för varje <xref:System.Speech.Recognition.SpeechRecognitionEngine>instans.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       Om tolken körs program använda <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>att pausa taligenkänningsmotorn före inläsning av, inaktivera, aktivera eller inaktivera en grammatik.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       När du läser in en grammatik aktiveras som standard. Om du vill inaktivera en läsa in grammatik, använda den <xref:System.Speech.Recognition.Grammar.Enabled%2A>egenskapen.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       Att läsa in en <xref:System.Speech.Recognition.Grammar>objekt asynkront, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar> and loads it into a speech recognizer.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SpeechRecognitionApp  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (  \n      SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Add a handler for the speech recognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous speech recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        while (true)  \n        {  \n          Console.ReadLine();  \n        }  \n      }  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Recognized text: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "Att läsa in grammatik objektet."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>är inte i ett giltigt tillstånd."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Läser in en speech recognition grammatik asynkront."
  remarks: "När tolken är klar läser in en <xref:System.Speech.Recognition.Grammar>objekt den genererar en <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted> </xref:System.Speech.Recognition.Grammar> Tolken genererar ett undantag om den <xref:System.Speech.Recognition.Grammar>objekt har redan lästs in, läses asynkront eller gick inte att läsa in i alla tolken.</xref:System.Speech.Recognition.Grammar> Du kan inte läsa in samma <xref:System.Speech.Recognition.Grammar>objekt till flera instanser av <xref:System.Speech.Recognition.SpeechRecognitionEngine>.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> I stället skapa ett nytt <xref:System.Speech.Recognition.Grammar>objekt för varje <xref:System.Speech.Recognition.SpeechRecognitionEngine>instans.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar>       Om tolken körs program använda <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>att pausa taligenkänningsmotorn före inläsning av, inaktivera, aktivera eller inaktivera en grammatik.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       När du läser in en grammatik aktiveras som standard. Om du vill inaktivera en läsa in grammatik, använda den <xref:System.Speech.Recognition.Grammar.Enabled%2A>egenskapen.</xref:System.Speech.Recognition.Grammar.Enabled%2A>       Om du vill läsa in en speech recognition grammatik synkront, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar%2A>"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "Tal recognition grammatik att läsa in."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "<code>Grammar</code>är inte i ett giltigt tillstånd."
  - type: System.OperationCanceledException
    commentId: T:System.OperationCanceledException
    description: "Den asynkrona åtgärden har avbrutits."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> är klar Asynkron inläsning av en <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt."
  remarks: "Tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A>metod som initierar en asynkron åtgärd.</xref:System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync%2A> Den <xref:System.Speech.Recognition.SpeechRecognitionEngine>genererar den här händelsen när åtgärden slutförts.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Att hämta <xref:System.Speech.Recognition.Grammar>objekt som tolken har lästs in, Använd <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>egenskapen i associerade <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs> </xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> </xref:System.Speech.Recognition.Grammar> Att hämta aktuellt <xref:System.Speech.Recognition.Grammar>objekt tolken har lästs in, använder tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A>egenskap.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Grammars%2A> </xref:System.Speech.Recognition.Grammar>       Om tolken körs program använda <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>att pausa taligenkänningsmotorn före inläsning av, inaktivera, aktivera eller inaktivera en grammatik.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       När du skapar en LoadGrammarCompleted delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example creates an in-process speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example constructs a <xref:System.Speech.Recognition.Grammar> object from each of the completed speech recognition grammars, then asynchronously loads the <xref:System.Speech.Recognition.Grammar> objects to the <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> events write to the console the name of the <xref:System.Speech.Recognition.Grammar> object that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and set its input.  \n      recognizer = new SpeechRecognitionEngine();  \n      recognizer.SetInputToDefaultAudioDevice();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted +=  \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Create the \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n      SemanticResultValue noValue =  \n          new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create the \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Start asynchronous, continuous recognition.  \n      recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar eller anger det maximala antalet alternativa resultat som den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> returnerar för varje recognition-åtgärd."
  remarks: "Den <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>egenskapen för den <xref:System.Speech.Recognition.RecognitionResult>klassen innehåller samlingen av <xref:System.Speech.Recognition.RecognizedPhrase>objekt som representerar möjliga tolkning av indata.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Standardvärdet för MaxAlternates är 10."
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "Antal alternativa resultat som ska returneras."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  exceptions:
  - type: System.ArgumentOutOfRangeException
    commentId: T:System.ArgumentOutOfRangeException
    description: "MaxAlternates har angetts till ett värde som är mindre än 0."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  id: QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Returnerar värden för inställningar för tolkning."
  remarks: "Tolkens inställningar kan innehålla sträng, 64-bitars heltal eller minne adressdata. I följande tabell beskrivs de inställningar som har definierats för en Microsoft Speech API (SAPI)-kompatibla identifierare. Följande inställningar måste ha samma intervall för varje identifierare som har stöd för inställningen. En SAPI-kompatibel identifierare kan behöver inte stöd för dessa inställningar och andra inställningar.      | Namnet | Beskrivning |   |----------|-----------------|   | `ResourceUsage`| Anger den tolken processoranvändningen. Intervallet är från 0 till 100. Standardvärdet är 50. |   | `ResponseSpeed`| Anger längden på tystnad i slutet av entydigt indata innan taligenkänningen har utfört en åtgärd med igenkänning. Intervallet är från 0 till 10 000 millisekunder (ms). Den här inställningen motsvarar tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>egenskap.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>  Standard = 150 MS. |   | `ComplexResponseSpeed`| Anger längden på tystnad i slutet av tvetydig indata innan taligenkänningen har utfört en åtgärd med igenkänning. Intervallet är från 0 till 10,000ms. Den här inställningen motsvarar tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>egenskap.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> Standard = 500ms. |   | `AdaptationOn`| Anger om anpassning av ljud modellen är aktiv (värde = `1`) eller OFF (värde = `0`). Standardvärdet är `1` (på). |   | `PersistedBackgroundAdaptation`| Anger om Bakgrundsanpassning är ON (värde = `1`) eller OFF (värde = `0`), och kvarstår inställningarna i registret. Standardvärdet är `1` (på). |       Om du vill uppdatera en inställning för tolkning med någon av de <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\"  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        foreach (string setting in settings)  \n        {  \n          try  \n          {  \n            object value = recognizer.QueryRecognizerSetting(setting);  \n            Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n          }  \n          catch  \n          {  \n            Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n              setting);  \n          }  \n        }  \n      }  \n      Console.WriteLine();  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public object QueryRecognizerSetting (string settingName);
    parameters:
    - id: settingName
      type: System.String
      description: "Namnet på inställningen för att returnera."
    return:
      type: System.Object
      description: "Värdet för inställningen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>är en tom sträng (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "Tolken är inte en inställning med det namnet."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  id: Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utför en synkron tal igenkänning."
  remarks: "Den här metoden utför en enda igenkänning. Tolken utför denna åtgärd mot sin inlästa och aktiverat tal recognition grammatik.       Under ett anrop till den här metoden tolken kan medföra följande händelser:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Utlöses när tolken identifierar indata som kan identifiera som tal.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Utlöses när indata skapar en tvetydig matchning med en aktiv grammatik.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Utlöses när tolken Slutför en recognition-åtgärd.       Tolken utlöser den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>händelsen när den här metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       Identifiera metoden returnerar en <xref:System.Speech.Recognition.RecognitionResult>objektet, eller `null` om det inte går att genomföra åtgärden.</xref:System.Speech.Recognition.RecognitionResult>       En synkron recognition misslyckas av följande skäl:-taligenkänning identifieras inte innan timeoutintervall som ska gälla för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>Egenskaper.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Motorn identifierar tal men inga matchningar har hittats i någon av dess inlästa och aktiverade <xref:System.Speech.Recognition.Grammar>objekt.</xref:System.Speech.Recognition.Grammar>       Använd en av för att utföra asynkron igenkänning av <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Modify the initial silence time-out value.  \n        recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5);  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize();  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize ();
    parameters: []
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Recognition resultatet för indata, eller <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> om det går inte att genomföra åtgärden eller tolken är inte aktiverad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  id: Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utför en synkron speech recognition med en angiven inledande tystnad timeout-period."
  remarks: "Om taligenkänningsmotorn identifierar tal inom den tidsperioden som anges av `initialSilenceTimeout` argument, identifiera utför en enda recognition och därefter avslutas.  Den `initialSilenceTimeout` parametern ersätter tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>egenskap.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>       Under ett anrop till den här metoden tolken kan medföra följande händelser:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Utlöses när tolken identifierar indata som kan identifiera som tal.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Utlöses när indata skapar en tvetydig matchning med en aktiv grammatik.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Utlöses när tolken Slutför en recognition-åtgärd.       Tolken utlöser den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>händelsen när den här metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>       Den <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>metoden returnerar en <xref:System.Speech.Recognition.RecognitionResult>objektet, eller `null` om det inte går att genomföra åtgärden.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize>       En synkron recognition misslyckas av följande skäl:-taligenkänning identifieras inte innan timeoutintervall som ska gälla för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>eller för den `initialSilenceTimeout` parametern.</xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Motorn identifierar tal men inga matchningar har hittats i någon av dess inlästa och aktiverade <xref:System.Speech.Recognition.Grammar>objekt.</xref:System.Speech.Recognition.Grammar>       Använd en av för att utföra asynkron igenkänning av <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one recognition operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SynchronousRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer for the en-US locale.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(  \n          new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        recognizer.LoadGrammar(new DictationGrammar());  \n  \n        // Configure input to the speech recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start synchronous speech recognition.  \n        RecognitionResult result = recognizer.Recognize(TimeSpan.FromSeconds(5));  \n  \n        if (result != null)  \n        {  \n          Console.WriteLine(\"Recognized text = {0}\", result.Text);  \n        }  \n        else  \n        {  \n          Console.WriteLine(\"No recognition result available.\");  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to continue...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult Recognize (TimeSpan initialSilenceTimeout);
    parameters:
    - id: initialSilenceTimeout
      type: System.TimeSpan
      description: "Tidsintervall inom vilket en taligenkänningen accepterar indata som innehåller endast tystnad innan du slutför igenkänning."
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "Recognition resultatet för indata, eller <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> om det går inte att genomföra åtgärden eller tolken är inte aktiverad."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  id: RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utför en enda, asynkron tal igenkänning."
  remarks: "Den här metoden utför en enda, asynkron igenkänning. Tolken utför åtgärd mot sin inlästa och aktiverat tal recognition grammatik.       Under ett anrop till den här metoden tolken kan medföra följande händelser:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Utlöses när tolken identifierar indata som kan identifiera som tal.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Utlöses när indata skapar en tvetydig matchning med en aktiv grammatik.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Utlöses när tolken Slutför en recognition-åtgärd.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Utlöses när en <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>åtgärden har slutförts.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Koppla en händelsehanterare för att hämta resultatet av en asynkron recognition till tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> Tolken genererar den här händelsen när den har slutfört en synkron eller asynkron åtgärd. Om recognition inte lyckades, den <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>egenskapen på <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>-objekt som du kan komma åt i hanteraren för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>händelse, blir `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       Använd en av för att utföra synkron igenkänning av <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs one asynchronous recognition operation. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[]   \n        { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start an asynchronous  \n        // recognition operation.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  id: RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utför en eller flera asynkrona speech recognition åtgärder."
  remarks: "Om `mode` är <xref:System.Speech.Recognition.RecognizeMode>, tolken fortsätter utför asynkrona recognition åtgärder förrän den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>-metoden anropas.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A> </xref:System.Speech.Recognition.RecognizeMode>       Under ett anrop till den här metoden tolken kan medföra följande händelser:- <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected>  Utlöses när tolken identifierar indata som kan identifiera som tal.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  Utlöses när indata skapar en tvetydig matchning med en aktiv grammatik.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> or <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> Utlöses när tolken Slutför en recognition-åtgärd.      -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Utlöses när en <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>åtgärden har slutförts.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Koppla en händelsehanterare för att hämta resultatet av en asynkron recognition till tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> Tolken genererar den här händelsen när den har slutfört en synkron eller asynkron åtgärd. Om recognition inte lyckades, den <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>egenskapen på <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>-objekt som du kan komma åt i hanteraren för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>händelse, blir `null`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.Result%2A>       En asynkron recognition åtgärd kan misslyckas på grund av följande:-taligenkänning identifieras inte innan timeoutintervall som ska gälla för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>Egenskaper.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>      -Motorn identifierar tal men inga matchningar har hittats i någon av dess inlästa och aktiverade <xref:System.Speech.Recognition.Grammar>objekt.</xref:System.Speech.Recognition.Grammar>       Använd en av för att utföra synkron igenkänning av <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>"
  example:
  - "The following example shows part of a console application that demonstrates basic asynchronous speech recognition. The example creates a <xref:System.Speech.Recognition.DictationGrammar>, loads it into an in-process speech recognizer, and performs multiple asynchronous recognition operations. The asynchronous operations are cancelled after 30 seconds. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create a grammar for choosing cities for a flight.  \n        Choices cities = new Choices(new string[] { \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I want to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Construct a Grammar object and load it to the recognizer.  \n        Grammar cityChooser = new Grammar(gb);  \n        cityChooser.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(cityChooser);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer and start asynchronous  \n        // recognition.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        completed = false;  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 30 seconds, and then cancel asynchronous recognition.  \n        Thread.Sleep(TimeSpan.FromSeconds(30));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n        Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsync (System.Speech.Recognition.RecognizeMode mode);
    parameters:
    - id: mode
      type: System.Speech.Recognition.RecognizeMode
      description: "Anger om du vill utföra en eller flera recognition åtgärder."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  id: RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Avbryter asynkron recognition utan att vänta på den aktuella recognition åtgärden ska slutföras."
  remarks: "Den här metoden Slutför omedelbart asynkron igenkänning. Om den aktuella åtgärden asynkron recognition tar emot indata, indata trunkeras och åtgärden har slutförts med befintliga indata. Tolken aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>händelse när en asynkron åtgärd har avbrutits och anger den <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>-egenskapen för den <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>till `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Den här metoden avbryter asynkrona åtgärder som initieras av den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Om du vill stoppa asynkrona recognition utan trunkera indata använder den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncCancel method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it cancels the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then cancel the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncCancel();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void RecognizeAsyncCancel ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  id: RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Stoppar asynkron recognition när den aktuella recognition-åtgärden har slutförts."
  remarks: "Den här metoden Slutför asynkron recognition utan trunkera indata. Om den aktuella åtgärden asynkron recognition tar emot indata, fortsätter tolken godtar tills den aktuella recognition-åtgärden har slutförts. Tolken aktiverar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted>händelse när en asynkron åtgärd har stoppats och anger den <xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A>-egenskapen för den <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>till `true`.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.ComponentModel.AsyncCompletedEventArgs.Cancelled%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> Den här metoden slutar asynkrona åtgärder som initieras av den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>       Om du vill avbryta omedelbart asynkron recognition med befintliga indata, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the use of the RecognizeAsyncStop method. The example creates and loads a speech recognition grammar, initiates a continuing asynchronous recognition operation, and then pauses 2 seconds before it stops the operation. The recognizer receives input from the file, c:\\temp\\audioinput\\sample.wav. Event handlers are included to demonstrate the events that the recognizer raises during the operation.  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace AsynchronousRecognition  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Create an in-process speech recognizer.  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        // Create and load a dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(  \n            SpeechDetectedHandler);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(  \n            SpeechHypothesizedHandler);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(  \n            SpeechRecognitionRejectedHandler);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Begin asynchronous recognition from pre-recorded input.  \n        recognizer.SetInputToWaveFile(@\"c:\\temp\\audioinput\\sample.wav\");  \n  \n        completed = false;  \n        Console.WriteLine(\"Begin continuing asynchronous recognition...\");  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait 2 seconds and then stop the recognition operation.  \n        Thread.Sleep(TimeSpan.FromSeconds(2));  \n        recognizer.RecognizeAsyncStop();  \n  \n        // Wait for the operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void SpeechDetectedHandler(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechDetectedHandler:\");  \n      Console.WriteLine(\" - AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void SpeechHypothesizedHandler(  \n      object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechHypothesizedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void SpeechRecognitionRejectedHandler(  \n      object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognitionRejectedHandler:\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\" In SpeechRecognizedHandler.\");  \n  \n      string grammarName = \"<not available>\";  \n      string resultText = \"<not available>\";  \n      if (e.Result != null)  \n      {  \n        if (e.Result.Grammar != null)  \n        {  \n          grammarName = e.Result.Grammar.Name;  \n        }  \n        resultText = e.Result.Text;  \n      }  \n  \n      Console.WriteLine(\" - Grammar Name = {0}; Result Text = {1}\",  \n        grammarName, resultText);  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\" In RecognizeCompletedHandler.\");  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \" - Error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\" - asynchronous operation canceled.\");  \n      }  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \" - BabbleTimeout = {0}; InitialSilenceTimeout = {1}\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \" - AudioPosition = {0}; InputStreamEnded = {1}\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(  \n          \" - Grammar = {0}; Text = {1}; Confidence = {2}\",  \n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\" - No result.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RecognizeAsyncStop ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  id: RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> Slutför en asynkron recognition-åtgärd."
  remarks: "Den <xref:System.Speech.Recognition.SpeechRecognitionEngine>objektets <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>metod som initierar en asynkron recognition åtgärd.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> När tolken Slutför den asynkrona åtgärden, genererar den här händelsen.       Med hjälp av hanteraren för händelsen RecognizeCompleted, du kan komma åt den <xref:System.Speech.Recognition.RecognitionResult>i den <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>objekt.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs> </xref:System.Speech.Recognition.RecognitionResult> Om recognition inte lyckades, <xref:System.Speech.Recognition.RecognitionResult>blir `null`.</xref:System.Speech.Recognition.RecognitionResult> För att avgöra om en tidsgräns eller ett avbrott i ljudinsignal beror på att misslyckas, kan du komma åt egenskaperna för <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A>, eller <xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A>.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout%2A> </xref:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout%2A>       Finns det <xref:System.Speech.Recognition.RecognizeCompletedEventArgs>klass för mer information.</xref:System.Speech.Recognition.RecognizeCompletedEventArgs>       För att få information om bästa nekade recognition kandidater kan koppla en hanterare för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>händelse.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>       När du skapar en RecognizeCompleted delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the RecognizeCompleted event to display information about the results of recognition in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n        recognizer.LoadGrammarCompleted +=   \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted, error occurred during recognition: {0}\", e.Error);  \n        return;  \n      }  \n  \n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\",  \n          e.BabbleTimeout, e.InitialSilenceTimeout);  \n        return;  \n      }  \n  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(  \n          \"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\",  \n          e.AudioPosition, e.InputStreamEnded);  \n      }  \n  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"RecognizeCompleted:\");  \n        Console.WriteLine(\"  Grammar: \" + e.Result.Grammar.Name);  \n        Console.WriteLine(\"  Recognized text: \" + e.Result.Text);  \n        Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n        Console.WriteLine(\"  Audio position: \" + e.AudioPosition);  \n      }  \n  \n      else  \n      {  \n        Console.WriteLine(\"RecognizeCompleted: No result.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded:  \" + e.Grammar.Name);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs> RecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar den aktuella platsen för den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> i ljudinsignal som den behandlar."
  remarks: "Ljud positionen är specifika för varje taligenkänningen. Värdet noll för en indataström upprättas när den är aktiverad.       RecognizerAudioPosition egenskapsreferenser i <xref:System.Speech.Recognition.SpeechRecognitionEngine>objektets position inom dess ljudinsignal.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Däremot kommer den <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>refererar till den indataenhet position i den genererade ljudströmmen.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> Dessa platser kan vara olika. Till exempel om tolken har tagit emot indata för vilka det har inte ännu genereras ett recognition resultat och sedan värdet på egenskapen RecognizerAudioPosition är mindre än värdet för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>egenskapen.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "Positionen för tolken i ljudinsignal som den behandlar."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Hämtar information om den aktuella instansen av <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>."
  remarks: "Om du vill få information om alla installerade taligenkänning för det aktuella systemet kan använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers%2A>"
  example:
  - "The following example gets a partial list of data for the current in-process speech recognition engine. For more information, see <xref:System.Speech.Recognition.RecognizerInfo>.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognitionEngine  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n        Console.WriteLine(\"Information for the current speech recognition engine:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "Information om aktuella taligenkänningsmotorn."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inträffar när en löpande <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> pausar att acceptera ändringar."
  remarks: "Program som måste använda <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>att pausa en pågående instans av <xref:System.Speech.Recognition.SpeechRecognitionEngine>innan du ändrar dess inställningar eller dess <xref:System.Speech.Recognition.Grammar>objekt.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Den <xref:System.Speech.Recognition.SpeechRecognitionEngine>genererar den här händelsen när den är redo att acceptera ändringar.</xref:System.Speech.Recognition.SpeechRecognitionEngine>       Till exempel när den <xref:System.Speech.Recognition.SpeechRecognitionEngine>är pausad, du kan läsa in, inaktivera, aktivera och inaktivera <xref:System.Speech.Recognition.Grammar>objekt och ändra värden för den <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>Egenskaper.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Mer information finns i <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>       När du skapar en RecognizerUpdateReached delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Begäranden om att tolken pausas för att uppdatera sitt tillstånd."
  remarks: "När tolken genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>händelse i <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>-egenskapen för den <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>är `null`.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       För att ge en användartoken, använda på <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>metod.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Ange en förskjutning på ljud position den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the RequestRecognizerUpdate method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognitionEngine recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize an in-process speech recognition engine and configure its input.  \n      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Create the first grammar - Farm.  \n        Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n        GrammarBuilder farm = new GrammarBuilder(animals);  \n        Grammar farmAnimals = new Grammar(farm);  \n        farmAnimals.Name = \"Farm\";  \n  \n        // Create the second grammar - Fruit.  \n        Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n        GrammarBuilder favorite = new GrammarBuilder(fruit);  \n        Grammar favoriteFruit = new Grammar(favorite);  \n        favoriteFruit.Name = \"Fruit\";  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizerUpdateReached +=  \n          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the Farm grammar.  \n        recognizer.LoadGrammar(farmAnimals);  \n  \n        // Start asynchronous, continuous recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n        Console.WriteLine(\"Starting asynchronous, continuous recognition\");  \n        Console.WriteLine(\"  Farm grammar is loaded and enabled.\");  \n  \n        // Pause to recognize farm animals.  \n        Thread.Sleep(7000);  \n        Console.WriteLine();  \n  \n        // Request an update and load the Fruit grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.LoadGrammarAsync(favoriteFruit);  \n        Thread.Sleep(7000);  \n  \n        // Request an update and unload the Farm grammar.  \n        recognizer.RequestRecognizerUpdate();  \n        recognizer.UnloadGrammar(farmAnimals);  \n        Thread.Sleep(7000);  \n      }  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  {0} grammar is loaded and {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Speech recognized: \" + e.Result.Text);  \n    }  \n  \n    // Write a message to the console when recognition fails.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"    Recognition attempt failed\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Begäranden att tolken pausas för att uppdatera sitt tillstånd och ger en användartoken för den associerade händelsen."
  remarks: "När tolken genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>händelse i <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>-egenskapen för den <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>innehåller värdet för den `userToken` parameter.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>       Ange en förskjutning på ljud position den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "Användardefinierad information som innehåller information för åtgärden."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Begäranden att tolken pausas för att uppdatera sitt tillstånd och ger en förskjutning och en användartoken för den associerade händelsen."
  remarks: "Tolken inte initiera begäran om uppdatering tolken förrän tolken <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>är lika med aktuellt <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A>plus `audioPositionAheadToRaiseUpdate`.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>       När tolken genererar den <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>händelse i <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>-egenskapen för den <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>innehåller värdet för den `userToken` parameter.</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "Användardefinierad information som innehåller information för åtgärden."
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "Förskjutning från aktuellt <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>att fördröja begäran.</xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*>"
  overload: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  id: SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Konfigurerar den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objekt som ska ta emot indata från en ljudström."
  remarks: "Om tolken når slutet av Indataströmmen under en åtgärd för igenkänning, slutför åtgärden recognition med tillgängliga indata. Alla åtgärder i efterföljande igenkänning kan generera ett undantag såvida inte du uppdatera indata till tolken."
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses input from an audio file, example.wav, that contains the phrases, \"testing testing one two three\" and \"mister cooper\", separated by a pause. The example generates the following output.  \n  \n```  \n  \nStarting asynchronous recognition...  \n  Recognized text =  Testing testing 123  \n  Recognized text =  Mr. Cooper  \n  End of stream encountered.  \nDone.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.IO;  \nusing System.Speech.AudioFormat;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace InputExamples  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition is complete.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \n        recognizer.SetInputToAudioStream(  \n          File.OpenRead(@\"c:\\temp\\audioinput\\example.wav\"),  \n          new SpeechAudioFormatInfo(  \n            44100, AudioBitsPerSample.Sixteen, AudioChannel.Mono));  \n  \n        // Attach event handlers.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Perform recognition of the whole file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n          e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToAudioStream (System.IO.Stream audioSource, System.Speech.AudioFormat.SpeechAudioFormatInfo audioFormat);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "Ljud Indataströmmen."
    - id: audioFormat
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "Formatet för ljud indata."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  id: SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Konfigurerar den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objekt som ska ta emot indata från standard ljudenhet."
  remarks: ''
  example:
  - "The following example shows part of a console application that demonstrates basic speech recognition. The example uses output from the default audio device, performs multiple, asynchronous recognition operations, and exits when a user utters the phrase, \"exit\".  \n  \n```c#  \n  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace DefaultInput  \n{  \n  class Program  \n  {  \n    // Indicate whether asynchronous recognition has finished.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create and load the exit grammar.  \n        Grammar exitGrammar = new Grammar(new GrammarBuilder(\"exit\"));  \n        exitGrammar.Name = \"Exit Grammar\";  \n        recognizer.LoadGrammar(exitGrammar);  \n  \n        // Create and load the dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers to the recognizer.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.RecognizeCompleted +=  \n          new EventHandler<RecognizeCompletedEventArgs>(  \n            RecognizeCompletedHandler);  \n  \n        // Assign input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Begin asynchronous recognition.  \n        Console.WriteLine(\"Starting recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Wait for recognition to finish.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized:\");  \n      string grammarName = \"<not available>\";  \n      if (e.Result.Grammar.Name != null &&  \n        !e.Result.Grammar.Name.Equals(string.Empty))  \n      {  \n        grammarName = e.Result.Grammar.Name;  \n      }  \n      Console.WriteLine(\"    {0,-17} - {1}\",  \n        grammarName, e.Result.Text);  \n  \n      if (grammarName.Equals(\"Exit Grammar\"))  \n      {  \n        ((SpeechRecognitionEngine)sender).RecognizeAsyncCancel();  \n      }  \n    }  \n  \n    static void RecognizeCompletedHandler(  \n      object sender, RecognizeCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Recognition completed.\");  \n      completed = true;  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void SetInputToDefaultAudioDevice ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  id: SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inaktiverar indata för taligenkänningen."
  remarks: "Konfigurera den <xref:System.Speech.Recognition.SpeechRecognitionEngine>objekt för någon åtgärd när du använder den <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>metoder, eller när du tar en taligenkänning tillfälligt offline.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>"
  syntax:
    content: public void SetInputToNull ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  id: SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Konfigurerar den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objekt att ta emot indata från en fil för Wave ljudformatet (.wav)."
  remarks: "Om tolken når slutet av filen under en åtgärd för igenkänning, slutför åtgärden recognition med tillgängliga indata. Alla åtgärder i efterföljande igenkänning kan generera ett undantag såvida inte du uppdatera indata till tolken."
  example:
  - "The following example performs recognition on the audio in a .wav file and writes the recognized text to the console.  \n  \n```  \nusing System;  \nusing System.IO;  \nusing System.Speech.Recognition;  \nusing System.Speech.AudioFormat;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Configure the input to the recognizer.  \nrecognizer.SetInputToWaveFile(@\"c:\\temp\\SampleWAVInput.wav\");  \n  \n        // Attach event handlers for the results of recognition.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.RecognizeCompleted +=   \n          new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \n  \n        // Perform recognition on the entire file.  \n        Console.WriteLine(\"Starting asynchronous recognition...\");  \n        completed = false;  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        while (!completed)  \n        {  \n          Console.ReadLine();  \n        }  \n        Console.WriteLine(\"Done.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n    }  \n  \n    // Handle the RecognizeCompleted event.  \n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \n    {  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"  Error encountered, {0}: {1}\",  \n        e.Error.GetType().Name, e.Error.Message);  \n      }  \n      if (e.Cancelled)  \n      {  \n        Console.WriteLine(\"  Operation cancelled.\");  \n      }  \n      if (e.InputStreamEnded)  \n      {  \n        Console.WriteLine(\"  End of stream encountered.\");  \n      }  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void SetInputToWaveFile (string path);
    parameters:
    - id: path
      type: System.String
      description: "Sökvägen till filen som ska användas som indata."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  id: SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Konfigurerar den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> objekt att ta emot indata från en dataström som innehåller data som Wave ljudformatet (.wav)."
  remarks: "Om tolken når slutet av Indataströmmen under en åtgärd för igenkänning, slutför åtgärden recognition med tillgängliga indata. Alla åtgärder i efterföljande igenkänning kan generera ett undantag såvida inte du uppdatera indata till tolken."
  syntax:
    content: public void SetInputToWaveStream (System.IO.Stream audioSource);
    parameters:
    - id: audioSource
      type: System.IO.Stream
      description: "Dataströmmen som innehåller ljuddata."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> identifierar indata som kan identifiera som tal."
  remarks: "Varje taligenkänningen har en algoritm för att skilja mellan tystnad och tal. När den <xref:System.Speech.Recognition.SpeechRecognitionEngine>utför en speech recognition, den genererar händelsen SpeechDetected när dess algoritmen identifierar indata som tal.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Den <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>egenskapen för den associerade <xref:System.Speech.Recognition.SpeechDetectedEventArgs>objektet anger plats i Indataströmmen där tolken identifieras tal.</xref:System.Speech.Recognition.SpeechDetectedEventArgs> </xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> Den <xref:System.Speech.Recognition.SpeechRecognitionEngine>aktiverar SpeechDetected händelse innan någon av de <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>, eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>händelser.</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognitionEngine>       Mer information finns i <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>       När du skapar en SpeechDetected delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=  \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> har identifierats av en eller flera ord som kan vara en del av flera hela fraser i en grammatik."
  remarks: "Den <xref:System.Speech.Recognition.SpeechRecognitionEngine>genererar ett flertal SpeechHypothesized händelser som försöker identifiera en inkommande fras.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Du kan komma åt texten för delvis tolkade fraser i den <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>egenskapen för den <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>objekt i hanteraren för händelsen SpeechHypothesized.</xref:System.Speech.Recognition.SpeechHypothesizedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Vanligtvis är hantera dessa händelser användbara endast för felsökning.       <xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>härleds från <xref:System.Speech.Recognition.RecognitionEventArgs>.</xref:System.Speech.Recognition.RecognitionEventArgs></xref:System.Speech.Recognition.SpeechHypothesizedEventArgs>       Mer information finns i <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>egenskap och <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>       När du skapar en SpeechHypothesized delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=  \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start asynchronous recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine();   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> tar emot indata som inte matchar någon av dess inlästa och aktiverade <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt."
  remarks: "Tolken genererar den här händelsen om det anger att indata inte överensstämmer med tillräckligt någon av dess inlästa och aktiverade <xref:System.Speech.Recognition.Grammar>objekt.</xref:System.Speech.Recognition.Grammar> Den <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>egenskapen för den <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>innehåller den nekade <xref:System.Speech.Recognition.RecognitionResult>objektet.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Du kan använda hanteraren för händelsen SpeechRecognitionRejected för att hämta recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>som avvisas och deras <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>poäng.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Om ditt program använder en <xref:System.Speech.Recognition.SpeechRecognitionEngine>instans, kan du ändra konfidensnivå på vilka tal indata godkännas eller avvisas av någon av de <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Du kan ändra hur taligenkänning ska svara på icke-ljudinspelning med hjälp av den <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Egenskaper.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       När du skapar en SpeechRecognitionRejected delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> to produce a successful recognition. The handler also displays recognition result <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> that were rejected because of low confidence scores.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n         new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=  \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync(RecognizeMode.Multiple);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n      foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n      {  \n      Console.WriteLine(\"  Rejected phrase: \" + phrase.Text);  \n      Console.WriteLine(\"  Confidence score: \" + phrase.Confidence);  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n      Console.WriteLine(\"  Confidence score: \" + e.Result.Confidence);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Utlöses när den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> tar emot indata som matchar någon av dess inlästa och aktiverade <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt."
  remarks: "Du kan starta en åtgärd för igenkänning använder du någon av de <xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A>eller <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.Recognize%2A> Tolken genererar händelsen SpeechRecognized om den avgör att indata matchar ett av dess inlästa <xref:System.Speech.Recognition.Grammar>objekt med tillräcklig förtroende att utgöra igenkänning.</xref:System.Speech.Recognition.Grammar> Den <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>egenskapen för den <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>innehåller den godkända <xref:System.Speech.Recognition.RecognitionResult>objektet.</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> Hanterare av SpeechRecognized händelser kan hämta frasen samt en lista över recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>med lägre förtroende poäng.</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       Om ditt program använder en <xref:System.Speech.Recognition.SpeechRecognitionEngine>instans, kan du ändra konfidensnivå på vilka tal indata godkännas eller avvisas av någon av de <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>metoder.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine>  Du kan ändra hur taligenkänning ska svara på icke-ljudinspelning med hjälp av den <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A>, och <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A>Egenskaper.</xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A> </xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>       När tolken tar emot indata som matchar en grammatik den <xref:System.Speech.Recognition.Grammar>objektet höja dess <xref:System.Speech.Recognition.Grammar.SpeechRecognized>händelse.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> Den <xref:System.Speech.Recognition.Grammar>objektets <xref:System.Speech.Recognition.Grammar.SpeechRecognized>händelse utlöses innan den taligenkänningen SpeechRecognized händelse.</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> Alla uppgifter som är specifika för en viss grammatik alltid ska utföras av en hanterare för den <xref:System.Speech.Recognition.Grammar.SpeechRecognized>händelse.</xref:System.Speech.Recognition.Grammar.SpeechRecognized>       När du skapar en SpeechRecognized delegat kan identifiera den metod som hanterar händelsen. Lägga till en instans av delegaten händelsen om du vill associera händelsen med din händelsehanterare. Händelsehanteraren anropas när händelsen inträffar, om du tar bort delegaten. Läs mer om händelsehanteraren delegater [händelser och delegater](http://go.microsoft.com/fwlink/?LinkId=162418)."
  example:
  - "The following example is part of a console application that creates speech recognition grammar, constructs a <xref:System.Speech.Recognition.Grammar> object, and loads it into the <xref:System.Speech.Recognition.SpeechRecognitionEngine> to perform recognition. The example demonstrates speech input to a <xref:System.Speech.Recognition.SpeechRecognitionEngine>, the associated recognition results, and the associated events raised by the speech recognizer.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize an in-process speech recognition engine.  \n    {  \n      using (SpeechRecognitionEngine recognizer = new SpeechRecognitionEngine())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Set the input to the recognizer.  \n        recognizer.SetInputToDefaultAudioDevice();  \n  \n        // Start recognition.  \n        recognizer.RecognizeAsync();  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "Som ska läggas till."
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Inaktiverar alla <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt från tolken."
  remarks: "Om tolken för närvarande läser in en <xref:System.Speech.Recognition.Grammar>asynkront, den här metoden ska vänta tills den <xref:System.Speech.Recognition.Grammar>har lästs in, innan det inaktiverar alla de <xref:System.Speech.Recognition.Grammar>objekt från den <xref:System.Speech.Recognition.SpeechRecognitionEngine>instans.</xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.Grammar>       Om du vill ta bort en specifik grammatik, använda den <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar%2A>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Tar bort en angiven <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref> objekt från den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> instans."
  remarks: "Om tolken körs program använda <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A>att pausa den <xref:System.Speech.Recognition.SpeechRecognitionEngine>instansen innan du läser in, inaktivera, aktivera eller inaktivera en <xref:System.Speech.Recognition.Grammar>objektet.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognitionEngine> </xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> Ta bort alla <xref:System.Speech.Recognition.Grammar>objekt, använder den <xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A>metoden.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.Grammar>"
  example:
  - "The following example shows part of a console application that demonstrates the synchronous loading and unloading of speech recognition grammars.  \n  \n```  \nLoading grammars...  \nLoaded grammars:  \n - Grammar1  \n - Grammar2  \n - Grammar3  \n  \nUnloading Grammar1...  \nLoaded grammars:  \n - Grammar2  \n - Grammar3  \n  \nUnloading all grammars...  \nNo grammars loaded.  \n  \nPress any key to exit...  \n```  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace UnloadGrammars  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Loading grammars...\");  \n  \n        // Create and load a number of grammars.  \n        Grammar grammar1 = new Grammar(new GrammarBuilder(\"first grammar\"));  \n        grammar1.Name = \"Grammar1\";  \n        recognizer.LoadGrammar(grammar1);  \n  \n        Grammar grammar2 = new Grammar(new GrammarBuilder(\"second grammar\"));  \n        grammar2.Name = \"Grammar2\";  \n        recognizer.LoadGrammar(grammar2);  \n  \n        Grammar grammar3 = new Grammar(new GrammarBuilder(\"third grammar\"));  \n        grammar3.Name = \"Grammar3\";  \n        recognizer.LoadGrammar(grammar3);  \n  \n        // List the recognizer's loaded grammars.  \n        ListGrammars(recognizer);  \n  \n        // Unload one grammar and list the loaded grammars.  \n        Console.WriteLine(\"Unloading Grammar1...\");  \n        recognizer.UnloadGrammar(grammar1);  \n        ListGrammars(recognizer);  \n  \n        // Unload all grammars and list the loaded grammars.  \n        Console.WriteLine(\"Unloading all grammars...\");  \n        recognizer.UnloadAllGrammars();  \n        ListGrammars(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListGrammars(SpeechRecognitionEngine recognizer)  \n    {  \n      // Make a copy of the recognizer's grammar collection.  \n      List<Grammar> loadedGrammars = new List<Grammar>(recognizer.Grammars);  \n  \n      if (loadedGrammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in recognizer.Grammars)  \n        {  \n          Console.WriteLine(\" - {0}\", g.Name);  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n```"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "Grammatik objekt att ta bort."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>Grammar</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.InvalidOperationException
    commentId: T:System.InvalidOperationException
    description: "Grammatik har inte lästs in i denna tolk eller denna tolk för närvarande läser in grammatik asynkront."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  id: UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Uppdaterar den angivna inställningen för den <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> med det angivna heltalsvärdet."
  remarks: "Med undantag av `PersistedBackgroundAdaptation`, egenskapsvärden som anges med metoden UpdateRecognizerSetting gäller endast för den aktuella instansen av <xref:System.Speech.Recognition.SpeechRecognitionEngine>, efter vilken de återgå till standardinställningarna.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Se <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>beskrivningar av inställningar som stöds.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  example:
  - "The following example is part of a console application that outputs the values for a number of the settings defined for the recognizer that supports the en-US locale. The example updates the confidence level settings, and then queries the recognizer to check the updated values. The example generates the following output.  \n  \n```  \nSettings for recognizer MS-1033-80-DESK:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 150  \n  ComplexResponseSpeed           = 500  \n  AdaptationOn                   = 1  \n  PersistedBackgroundAdaptation  = 1  \n  \nUpdated settings:  \n  \n  ResourceUsage                  is not supported by this recognizer.  \n  ResponseSpeed                  = 200  \n  ComplexResponseSpeed           = 300  \n  AdaptationOn                   = 0  \n  PersistedBackgroundAdaptation  = 0  \n  \nPress any key to exit...  \n```  \n  \n```c#  \nusing System;  \nusing System.Globalization;  \nusing System.Speech.Recognition;  \n  \nnamespace RecognizerSettings  \n{  \n  class Program  \n  {  \n    static readonly string[] settings = new string[] {  \n      \"ResourceUsage\",  \n      \"ResponseSpeed\",  \n      \"ComplexResponseSpeed\",  \n      \"AdaptationOn\",  \n      \"PersistedBackgroundAdaptation\",  \n    };  \n  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognitionEngine recognizer =  \n        new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\"en-US\")))  \n      {  \n        Console.WriteLine(\"Settings for recognizer {0}:\",  \n          recognizer.RecognizerInfo.Name);  \n        Console.WriteLine();  \n  \n        // List the current settings.  \n        ListSettings(recognizer);  \n  \n        // Change some of the settings.  \n        recognizer.UpdateRecognizerSetting(\"ResponseSpeed\", 200);  \n        recognizer.UpdateRecognizerSetting(\"ComplexResponseSpeed\", 300);  \n        recognizer.UpdateRecognizerSetting(\"AdaptationOn\", 1);  \n        recognizer.UpdateRecognizerSetting(\"PersistedBackgroundAdaptation\", 0);  \n  \n        Console.WriteLine(\"Updated settings:\");  \n        Console.WriteLine();  \n  \n        // List the updated settings.  \n        ListSettings(recognizer);  \n      }  \n  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void ListSettings(SpeechRecognitionEngine recognizer)  \n    {  \n      foreach (string setting in settings)  \n      {  \n        try  \n        {  \n          object value = recognizer.QueryRecognizerSetting(setting);  \n          Console.WriteLine(\"  {0,-30} = {1}\", setting, value);  \n        }  \n        catch  \n        {  \n          Console.WriteLine(\"  {0,-30} is not supported by this recognizer.\",  \n            setting);  \n        }  \n      }  \n      Console.WriteLine();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, int updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "Namnet på inställningen för att uppdatera."
    - id: updatedValue
      type: System.Int32
      description: "Det nya värdet för inställningen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>är en tom sträng (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "Tolken är inte en inställning med det namnet."
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  id: UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  langs:
  - csharp
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Uppdaterar inställningen angivna speech recognition motorn med strängvärdet."
  remarks: "Med undantag av `PersistedBackgroundAdaptation`, egenskapsvärden som anges med metoden UpdateRecognizerSetting gäller endast för den aktuella instansen av <xref:System.Speech.Recognition.SpeechRecognitionEngine>, efter vilken de återgå till standardinställningarna.</xref:System.Speech.Recognition.SpeechRecognitionEngine> Se <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>beskrivningar av inställningar som stöds.</xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A>"
  syntax:
    content: public void UpdateRecognizerSetting (string settingName, string updatedValue);
    parameters:
    - id: settingName
      type: System.String
      description: "Namnet på inställningen för att uppdatera."
    - id: updatedValue
      type: System.String
      description: "Det nya värdet för inställningen."
  overload: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  exceptions:
  - type: System.ArgumentNullException
    commentId: T:System.ArgumentNullException
    description: "<code>settingName</code>is <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>."
  - type: System.ArgumentException
    commentId: T:System.ArgumentException
    description: "<code>settingName</code>är en tom sträng (&quot;&quot;)."
  - type: System.Collections.Generic.KeyNotFoundException
    commentId: T:System.Collections.Generic.KeyNotFoundException
    description: "Tolken är inte en inställning med det namnet."
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.ArgumentException
  isExternal: true
  name: System.ArgumentException
- uid: System.ArgumentNullException
  isExternal: true
  name: System.ArgumentNullException
- uid: System.ArgumentOutOfRangeException
  isExternal: true
  name: System.ArgumentOutOfRangeException
- uid: System.InvalidOperationException
  isExternal: true
  name: System.InvalidOperationException
- uid: System.NotSupportedException
  isExternal: true
  name: System.NotSupportedException
- uid: System.OperationCanceledException
  isExternal: true
  name: System.OperationCanceledException
- uid: System.Collections.Generic.KeyNotFoundException
  isExternal: true
  name: System.Collections.Generic.KeyNotFoundException
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine()
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Globalization.CultureInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(CultureInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(CultureInfo)
- uid: System.Globalization.CultureInfo
  parent: System.Globalization
  isExternal: true
  name: CultureInfo
  nameWithType: CultureInfo
  fullName: System.Globalization.CultureInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.Speech.Recognition.RecognizerInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(RecognizerInfo)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(RecognizerInfo)
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine(String)
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionEngine(String)
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognitionEngine.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognitionEngine.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognitionEngine.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognitionEngine.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognitionEngine.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers()
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers()
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizerInfo}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizerInfo>
  nameWithType: ReadOnlyCollection<RecognizerInfo>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizerInfo>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerInfo
    name: RecognizerInfo
    nameWithType: RecognizerInfo
    fullName: RecognizerInfo
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognitionEngine.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting(String)
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize()
  nameWithType: SpeechRecognitionEngine.Recognize()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize(TimeSpan)
  nameWithType: SpeechRecognitionEngine.Recognize(TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.Recognize(TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync()
  nameWithType: SpeechRecognitionEngine.RecognizeAsync()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(System.Speech.Recognition.RecognizeMode)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync(RecognizeMode)
  nameWithType: SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync(RecognizeMode)
- uid: System.Speech.Recognition.RecognizeMode
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizeMode
  nameWithType: RecognizeMode
  fullName: System.Speech.Recognition.RecognizeMode
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop()
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeCompleted
  nameWithType: SpeechRecognitionEngine.RecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.RecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizeCompletedEventArgs>
  nameWithType: EventHandler<RecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizeCompletedEventArgs
    name: RecognizeCompletedEventArgs
    nameWithType: RecognizeCompletedEventArgs
    fullName: RecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognitionEngine.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(System.IO.Stream,System.Speech.AudioFormat.SpeechAudioFormatInfo)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream(Stream,SpeechAudioFormatInfo)
- uid: System.IO.Stream
  parent: System.IO
  isExternal: true
  name: Stream
  nameWithType: Stream
  fullName: System.IO.Stream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice()
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull()
  nameWithType: SpeechRecognitionEngine.SetInputToNull()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile(String)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile(String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile(String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(System.IO.Stream)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream(Stream)
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream(Stream)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream(Stream)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognitionEngine.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognitionEngine.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognitionEngine.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognitionEngine.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.Int32)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,Int32)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,Int32)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(System.String,System.String)
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting(String,String)
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
  fullName: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting(String,String)
- uid: System.Speech.Recognition.SpeechRecognitionEngine.#ctor*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SpeechRecognitionEngine
  nameWithType: SpeechRecognitionEngine.SpeechRecognitionEngine
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognitionEngine.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognitionEngine.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognitionEngine.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.AudioState*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognitionEngine.AudioState
- uid: System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: BabbleTimeout
  nameWithType: SpeechRecognitionEngine.BabbleTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Dispose*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognitionEngine.Dispose
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognitionEngine.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognitionEngine.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeout
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: EndSilenceTimeoutAmbiguous
  nameWithType: SpeechRecognitionEngine.EndSilenceTimeoutAmbiguous
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Grammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognitionEngine.Grammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InitialSilenceTimeout
  nameWithType: SpeechRecognitionEngine.InitialSilenceTimeout
- uid: System.Speech.Recognition.SpeechRecognitionEngine.InstalledRecognizers*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: InstalledRecognizers
  nameWithType: SpeechRecognitionEngine.InstalledRecognizers
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognitionEngine.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognitionEngine.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognitionEngine.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognitionEngine.QueryRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: QueryRecognizerSetting
  nameWithType: SpeechRecognitionEngine.QueryRecognizerSetting
- uid: System.Speech.Recognition.SpeechRecognitionEngine.Recognize*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: Recognize
  nameWithType: SpeechRecognitionEngine.Recognize
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsync
  nameWithType: SpeechRecognitionEngine.RecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncCancel*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncCancel
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncCancel
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsyncStop*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizeAsyncStop
  nameWithType: SpeechRecognitionEngine.RecognizeAsyncStop
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognitionEngine.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognitionEngine.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognitionEngine.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToAudioStream
  nameWithType: SpeechRecognitionEngine.SetInputToAudioStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToDefaultAudioDevice*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToDefaultAudioDevice
  nameWithType: SpeechRecognitionEngine.SetInputToDefaultAudioDevice
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToNull*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToNull
  nameWithType: SpeechRecognitionEngine.SetInputToNull
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveFile
  nameWithType: SpeechRecognitionEngine.SetInputToWaveFile
- uid: System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveStream*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: SetInputToWaveStream
  nameWithType: SpeechRecognitionEngine.SetInputToWaveStream
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognitionEngine.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognitionEngine.UnloadGrammar
- uid: System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting*
  parent: System.Speech.Recognition.SpeechRecognitionEngine
  isExternal: false
  name: UpdateRecognizerSetting
  nameWithType: SpeechRecognitionEngine.UpdateRecognizerSetting
